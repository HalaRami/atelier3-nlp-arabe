# Atelier 3 - Deep Learning : NLP Arabe avec PyTorch et Transformers

## Objectif
Familiarisation avec PyTorch pour les modèles séquentiels (RNN, BiRNN, GRU, LSTM) et génération de texte avec GPT2 arabe.

## Partie 1 : Régression (Prédiction de Score de Pertinence)
- Dataset : SANAD (catégorie Tech) via Hugging Face.
- Prétraitement : PyArabic (normalisation) + NLTK (stop words).
- Modèles : RNN, BiRNN, GRU, LSTM.
- Évaluation : MSE, MAE, R².

## Partie 2 : Génération de Texte
- Modèle : AraGPT2-base fine-tuné sur articles Tech.
- Exemple de génération inclus.

## Exécution
Ouvrir le notebook Colab et exécuter les cellules dans l'ordre.

## Synthèse
Maîtrise de PyTorch, pipeline NLP arabe, comparaison de modèles séquentiels et fine-tuning Transformer.

Références :  
- SANAD Dataset  
- AraGPT2 : aubmindlab/aragpt2-base


